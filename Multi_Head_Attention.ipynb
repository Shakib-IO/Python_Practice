{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyFAzxOnhw3g8AljJ/slbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shakib-IO/Python_Practice/blob/main/Multi_Head_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Medium](https://medium.com/@hunter-j-phillips/multi-head-attention-7924371d477a)"
      ],
      "metadata": {
        "id": "EAPywq6sbTjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "jZz65CRAN_lt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Input\n",
        "- X has a size of **(batch_size, seq_length, d_model)**. For example, a batch of 32 sequences of length 10 with an embedding of 512, which would have a shape of **(32, 10, 512)**.\n",
        "- Wq, Wk, and Wv have a size of **(d_model, d_model)**. Following the example above, they would have a shape of **(512, 512)**.\n",
        "- **Q = XWq** | (batch_size, seq_length, d_model) x (d_model, d_model) = (**batch_size, seq_length, d_model)**\n",
        "- **K = XWk** | (batch_size, seq_length, d_model) x (d_model, d_model) = **(batch_size, seq_length, d_model)**\n",
        "- **V = XWv** | (batch_size, seq_length, d_model) x (d_model, d_model) = **(batch_size, seq_length, d_model)**"
      ],
      "metadata": {
        "id": "DfWGmF2PQRPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Sample Input"
      ],
      "metadata": {
        "id": "5EVhKQ9iS3ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main String\n",
        "sequences = [\"I wonder what will come next!\",\n",
        "             \"This is a basic example paragraph.\",\n",
        "             \"Hello, what is a basic split?\"]"
      ],
      "metadata": {
        "id": "NHOhC2__U5hG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sequence):\n",
        "  # remove punctuation\n",
        "  for punc in [\"!\", \".\", \"?\"]:\n",
        "    sequence = sequence.replace(punc, \"\")\n",
        "\n",
        "  # split the sequence on spaces and lowercase each token\n",
        "  return [token.lower() for token in sequence.split(\" \")]"
      ],
      "metadata": {
        "id": "JeN8xYcEQU41"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "  # Join the sequences into a single string before tokenization\n",
        "  data_str = \" \".join(data)\n",
        "\n",
        "  # tokenize the data and remove duplicates\n",
        "  vocab = list(set(tokenize(data_str))) # Pass the combined string to tokenize\n",
        "\n",
        "  # sort the vocabulary\n",
        "  vocab.sort()\n",
        "\n",
        "  # assign an integer to each word\n",
        "  stoi = {word:i for i, word in enumerate(vocab)}\n",
        "\n",
        "  return stoi\n",
        "\n",
        "# Pass the list of sequences directly to build_vocab\n",
        "stoi = build_vocab(sequences)"
      ],
      "metadata": {
        "id": "gbmkE5LSV_Nn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model: int, dropout: float = 0.1, max_length: int = 5000):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      d_model:      dimension of embeddings\n",
        "      dropout:      randomly zeroes-out some of the input\n",
        "      max_length:   max sequence length\n",
        "    \"\"\"\n",
        "    # inherit from Module\n",
        "    super().__init__()\n",
        "\n",
        "    # initialize dropout\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    # create tensor of 0s\n",
        "    pe = torch.zeros(max_length, d_model)\n",
        "\n",
        "    # create position column\n",
        "    k = torch.arange(0, max_length).unsqueeze(1)\n",
        "\n",
        "    # calc divisor for positional encoding\n",
        "    div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "    )\n",
        "\n",
        "    # calc sine on even indices\n",
        "    pe[:, 0::2] = torch.sin(k * div_term)\n",
        "\n",
        "    # calc cosine on odd indices\n",
        "    pe[:, 1::2] = torch.cos(k * div_term)\n",
        "\n",
        "    # add dimension\n",
        "    pe = pe.unsqueeze(0)\n",
        "\n",
        "    # buffers are saved in state_dict but not trained by the optimizer\n",
        "    self.register_buffer(\"pe\", pe)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      x:        embeddings (batch_size, seq_length, d_model)\n",
        "\n",
        "    Returns:\n",
        "                embeddings + positional encodings (batch_size, seq_length, d_model)\n",
        "    \"\"\"\n",
        "    # add positional encoding to the embeddings\n",
        "    x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "\n",
        "    # perform dropout\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "9wwztc3SZTpB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sequences = [tokenize(seq) for seq in sequences]\n",
        "\n",
        "# convert the sequences to integers\n",
        "indexed_sequences = [[stoi[word] for word in seq] for seq in tokenized_sequences]\n",
        "\n",
        "# conver thr sequence to a tensor\n",
        "tensor_seq = torch.tensor(indexed_sequences).long() # 3x6\n",
        "\n",
        "# Vocab_size\n",
        "vocab_size = len(stoi) # 14\n",
        "\n",
        "# D_model (Embedding Dimention)\n",
        "d_model = 8\n",
        "\n",
        "# Create the Embeddings\n",
        "emb = nn.Embedding(vocab_size, d_model) # Create an embedding size of (14, 8)\n",
        "\n",
        "# Positional Embedding\n",
        "pos_embd = PositionalEncoding(d_model=d_model, dropout=0.1, max_length=10)\n",
        "\n",
        "# Embedded the Sequebce\n",
        "lut = emb(tensor_seq) # torch.Size([3, 6, 8])\n",
        "\n",
        "# Add the positional encodings\n",
        "X = pos_embd(lut)\n",
        "X # torch.Size([3, 6, 8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTmacJo6S8fn",
        "outputId": "07722379-0f16-4bcd-d217-9b1816f54704"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9965,  0.0000, -0.1276, -0.1866, -0.0046,  0.1521, -1.7051,\n",
              "           1.3467],\n",
              "         [ 0.7666,  3.9468, -0.3194,  2.2877,  0.0000,  0.5118, -0.4217,\n",
              "           1.7311],\n",
              "         [ 0.6534, -0.3180,  0.0492, -1.0483, -0.0000,  1.9002, -1.1002,\n",
              "           1.9462],\n",
              "         [-0.8726, -1.5124, -0.1749, -0.2964,  1.4201,  0.1977, -0.4234,\n",
              "           2.9098],\n",
              "         [-0.8739, -1.9751, -1.6096,  1.1916, -0.2003,  0.0000,  0.9831,\n",
              "          -0.4254],\n",
              "         [-0.2143,  0.6313,  1.1066, -0.6754, -1.7632,  1.9809,  1.3412,\n",
              "           1.7196]],\n",
              "\n",
              "        [[-0.0000,  2.1747, -2.0839,  2.8800, -0.7512,  1.8371, -0.2812,\n",
              "           0.0000],\n",
              "         [ 2.9189,  0.5060, -1.7257,  0.5813,  0.0000,  2.0329,  0.7927,\n",
              "           0.6572],\n",
              "         [ 1.2726, -0.1309, -0.7897,  1.2685,  0.6416,  0.0000, -0.1389,\n",
              "           1.3736],\n",
              "         [ 1.1722, -0.2704, -0.2394,  1.1643,  0.0000, -0.0357,  0.4561,\n",
              "           1.3206],\n",
              "         [-1.1534, -0.2791,  0.0000, -1.3569, -0.3477, -1.4234,  1.1846,\n",
              "           2.0221],\n",
              "         [-1.1335, -1.2319,  0.0455,  1.3555, -0.7563,  1.9756, -0.0000,\n",
              "           0.6699]],\n",
              "\n",
              "        [[ 0.8878, -0.5111,  0.3373,  1.0563, -0.0707, -0.0742, -2.2278,\n",
              "           3.1191],\n",
              "         [ 0.5781,  0.7447, -0.0606, -1.0317, -0.2450,  1.9004, -1.1013,\n",
              "           1.9462],\n",
              "         [ 2.9943, -0.5567, -1.6159,  0.5647,  0.1001,  2.0328,  0.7938,\n",
              "           0.6572],\n",
              "         [ 0.4191, -0.7685, -0.6821,  1.2410,  0.6527,  1.9043, -0.1378,\n",
              "           1.3736],\n",
              "         [ 0.1745,  0.1033, -0.1351,  1.1263,  1.1404, -0.0361,  0.4572,\n",
              "           1.3205],\n",
              "         [ 0.5288,  0.7410,  1.8495,  1.1630, -1.8800,  1.1890,  0.0252,\n",
              "          -0.8885]]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, the embedded sequences, **X**, have a shape of **(3, 6, 8)**. There are **3 sequences** of **6 tokens** with an **8 dimensional embedding**."
      ],
      "metadata": {
        "id": "F1Zafrk5aLCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets create Wq, Wk, Wv\n",
        "Wq = nn.Linear(in_features=d_model, out_features=d_model, bias=False) # Wq = 8x8\n",
        "Wk = nn.Linear(in_features=d_model, out_features=d_model, bias=False)  # Wk = 8x8\n",
        "Wv = nn.Linear(in_features=d_model, out_features=d_model, bias=False) # Wk = 8x8\n",
        "\n",
        "Wq.state_dict()['weight']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4yVH6H1aY2g",
        "outputId": "6989992b-4d71-41c3-c8f5-005665308350"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3407,  0.1125,  0.0422,  0.0085, -0.2184,  0.1037, -0.2194, -0.0895],\n",
              "        [ 0.1059, -0.1269,  0.0787, -0.0451, -0.3095,  0.2400, -0.1946,  0.3119],\n",
              "        [-0.2710, -0.0675, -0.2163, -0.0774,  0.3440,  0.0519,  0.0586, -0.0065],\n",
              "        [ 0.0851,  0.0432, -0.2403,  0.0841, -0.2135, -0.1283, -0.1478,  0.1103],\n",
              "        [ 0.3269,  0.2589,  0.2757,  0.0331, -0.2540,  0.0685,  0.2441,  0.1574],\n",
              "        [ 0.2386,  0.0038, -0.1266, -0.0983, -0.1232,  0.1283, -0.0568,  0.3321],\n",
              "        [-0.2552, -0.3156,  0.3358,  0.0693, -0.2996, -0.3025,  0.3484,  0.0366],\n",
              "        [ 0.0500, -0.1178, -0.1273,  0.3405,  0.0551,  0.2097,  0.0049,  0.0223]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now transform Q, K, V"
      ],
      "metadata": {
        "id": "e050NUNKa8oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = Wq(X) # (batch_size, seq_length, d_model) x (d_model, d_model) = (batch_size, seq_length, d_model)\n",
        "K = Wk(X) # (batch_size, seq_length, d_model) x (d_model, d_model) = (batch_size, seq_length, d_model)\n",
        "V = Wv(X) # (batch_size, seq_length, d_model) x (d_model, d_model) = (batch_size, seq_length, d_model)\n",
        "\n",
        "Q # (3, 6, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW-RuJWFbAAz",
        "outputId": "d74fe696-fd2c-419e-8269-a19559755dc0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-7.6132e-02,  6.8265e-01,  2.0964e-01,  3.1220e-01, -5.5975e-01,\n",
              "           3.6098e-01, -3.9090e-01, -4.3866e-02],\n",
              "         [ 7.0210e-01,  1.9695e-01, -5.9135e-01,  6.9222e-01,  1.4647e+00,\n",
              "           6.7790e-01, -1.6283e+00,  5.3686e-01],\n",
              "         [ 4.4426e-01,  1.4378e+00, -6.3673e-02,  7.5431e-02,  2.7797e-01,\n",
              "           1.2043e+00, -1.0094e+00,  1.4339e-01],\n",
              "         [-9.3462e-01,  6.9696e-01,  8.5428e-01, -6.7560e-02, -7.2747e-01,\n",
              "           6.7827e-01,  9.4413e-02,  2.3817e-01],\n",
              "         [-7.1157e-01, -2.8423e-01,  6.1754e-01,  1.7791e-01, -9.7733e-01,\n",
              "          -3.0176e-01,  7.7525e-01,  7.8374e-01],\n",
              "         [ 1.8155e-01,  1.3111e+00, -6.0809e-01, -1.9994e-01,  1.5574e+00,\n",
              "           8.4386e-01,  6.3969e-01, -9.2711e-02]],\n",
              "\n",
              "        [[ 5.9778e-01,  1.5845e-01, -9.8266e-02,  8.0302e-01,  3.3197e-01,\n",
              "           3.3321e-01, -1.6152e+00,  1.3321e+00],\n",
              "         [ 9.6169e-01,  6.2157e-01, -3.4899e-01,  4.2831e-01,  1.0649e+00,\n",
              "           1.2939e+00, -1.7586e+00,  9.4875e-01],\n",
              "         [ 1.6373e-01,  2.8900e-01, -5.9697e-02,  4.3408e-01,  2.2577e-01,\n",
              "           6.6347e-01, -6.5115e-01,  6.7667e-01],\n",
              "         [ 1.4681e-01,  4.0173e-01, -3.2143e-01,  3.2630e-01,  6.0241e-01,\n",
              "           6.0255e-01,  4.5210e-03,  5.4151e-01],\n",
              "         [-9.4842e-01,  1.4057e-01,  2.9902e-01,  8.0469e-02,  1.0386e-01,\n",
              "           3.2161e-01,  1.3100e+00, -7.5365e-01],\n",
              "         [-2.0109e-01,  8.9590e-01,  1.1351e-01, -6.4686e-02, -1.9920e-01,\n",
              "           1.5502e-01,  4.4076e-01,  9.3165e-01]],\n",
              "\n",
              "        [[ 4.8547e-01,  1.5483e+00, -5.3989e-01,  7.5913e-01,  2.4583e-01,\n",
              "           1.2249e+00, -4.9715e-01,  4.6043e-01],\n",
              "         [ 5.8748e-01,  1.3617e+00, -1.7681e-01,  1.9512e-01,  5.6070e-01,\n",
              "           1.2329e+00, -1.2883e+00,  2.0630e-02],\n",
              "         [ 8.5013e-01,  7.4257e-01, -2.8572e-01,  3.3957e-01,  8.1895e-01,\n",
              "           1.2831e+00, -1.4363e+00,  1.0635e+00],\n",
              "         [ 3.9773e-04,  7.4256e-01,  2.9618e-01,  5.8912e-02, -6.1667e-02,\n",
              "           6.8947e-01, -7.7687e-01,  1.0860e+00],\n",
              "         [-3.9633e-01, -9.4751e-02,  2.9647e-01, -1.4395e-02,  1.1112e-01,\n",
              "           2.1588e-01, -1.6761e-01,  4.8406e-01],\n",
              "         [ 9.5950e-01,  6.4030e-01, -1.2612e+00, -1.2246e-01,  1.3383e+00,\n",
              "          -1.3197e-01,  5.1285e-01,  2.2596e-01]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Q, K, and V Into Their Heads <br>\n",
        "**d_key = (d_model / n_heads)** <br>\n",
        "Q contains (batch_size, seq, d_model) now, the d_model will split and become the row and column. Now Q will have (batch_size, seq, row, col) or (batch_size, seq, n_heads, d_key). <br>\n",
        "\n",
        "The shape of each tensor becomes:\n",
        "\n",
        "**(batch_size, seq_length, d_model) → (batch_size, seq_length, n_heads, d_key)**\n"
      ],
      "metadata": {
        "id": "yl0sVcxLbdJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = Q.size(0)\n",
        "n_heads = 4\n",
        "d_key = d_model//n_heads # 8/4 = 2\n",
        "\n",
        "# query tensor | -1 = query_length | (3, 6, 8) -> (3, 6, 4, 2)\n",
        "Q = Q.view(batch_size, -1, n_heads, d_key)\n",
        "\n",
        "# value tensor | -1 = key_length | (3, 6, 8) -> (3, 6, 4, 2)\n",
        "K = K.view(batch_size, -1, n_heads, d_key)\n",
        "\n",
        "# value tensor | -1 = value_length | (3, 6, 8) -> (3, 6, 4, 2)\n",
        "V = V.view(batch_size, -1, n_heads, d_key)\n",
        "\n",
        "Q.shape #torch.Size([3, 6, 4, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvdiVdE1bfim",
        "outputId": "6c8d14a9-513f-4bcc-93ea-7c27834f0279"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 6, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To proceed, it would be best to **transpose seq_length and n_heads**, the second and third dimensions, to have the following shape:\n",
        "\n",
        "**(batch_size, seq_length, n_heads, d_key) → (batch_size, n_heads, seq_length, d_key)**"
      ],
      "metadata": {
        "id": "WJ6CsH47c136"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query tensor | (3, 6, 4, 2) -> (3, 4, 6, 2)\n",
        "Q = Q.permute(0, 2, 1, 3)\n",
        "# key tensor | (3, 6, 4, 2) -> (3, 4, 6, 2)\n",
        "K = K.permute(0, 2, 1, 3)\n",
        "# value tensor | (3, 6, 4, 2) -> (3, 4, 6, 2)\n",
        "V = V.permute(0, 2, 1, 3)\n",
        "\n",
        "Q.shape # torch.Size([3, 4, 6, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JZEMSu6c2jI",
        "outputId": "c254e0c4-44ee-4c4a-e7ad-3c77a931827b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Scale-dot multiplication. <br>\n",
        "Moving forward, the seq_length shape of each tensor will be known by its respective tensor for clarity, **Q_length, K_length, or V_length**:\n",
        "\n",
        "Q has a shape of **(batch_size, n_heads, Q_length, d_key)**\n",
        "K has a shape of (batch_size, n_heads, K_length, d_key)\n",
        "V has a shape of (batch_size, n_heads, V_length, d_key)\n",
        "The two rightmost dimensions of K must be transposed to change the shape to **(batch_size, n_heads, d_key, K_length)**.\n",
        "\n",
        "**QK^T** will be:\n",
        "\n",
        "**(batch_size, n_heads, Q_length, d_key) x (batch_size, n_heads, d_key, K_length) = (batch_size, n_heads, Q_length, K_length)**"
      ],
      "metadata": {
        "id": "6f2XaKvMeBFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate scaled dot product\n",
        "scaled_dot_prod = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(d_key) # (batch_size, n_heads, Q_length, K_length) | (3, 4, 6, 2) x (3, 4, 2, 6) = (3, 4, 6, 6).\n",
        "scaled_dot_prod.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHUORu_sdCmW",
        "outputId": "a21982d7-80c1-4cd5-91ce-526cde6982dc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply softmax to get context for each token and others\n",
        "attn_probs = torch.softmax(scaled_dot_prod, dim=-1) # (batch_size, n_heads, Q_length, K_length)\n",
        "attn_probs #torch.Size([3, 4, 6, 6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yLBiSaGewxs",
        "outputId": "b5f18ee9-5e53-49ee-e952-2d6b1a69097b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.1835, 0.1388, 0.1919, 0.2339, 0.1192, 0.1328],\n",
              "          [0.1772, 0.3405, 0.1523, 0.1667, 0.0790, 0.0843],\n",
              "          [0.2000, 0.2049, 0.1916, 0.2990, 0.0455, 0.0589],\n",
              "          [0.1412, 0.0446, 0.1795, 0.2113, 0.2042, 0.2192],\n",
              "          [0.1195, 0.0632, 0.1388, 0.1235, 0.2886, 0.2664],\n",
              "          [0.1980, 0.1614, 0.2003, 0.2975, 0.0634, 0.0793]],\n",
              "\n",
              "         [[0.1984, 0.1242, 0.1818, 0.1829, 0.1701, 0.1427],\n",
              "          [0.1583, 0.0692, 0.1294, 0.2191, 0.3058, 0.1182],\n",
              "          [0.1675, 0.1530, 0.1639, 0.1735, 0.1798, 0.1622],\n",
              "          [0.2086, 0.1929, 0.2141, 0.1381, 0.0921, 0.1542],\n",
              "          [0.2152, 0.1492, 0.2055, 0.1620, 0.1230, 0.1450],\n",
              "          [0.1236, 0.1834, 0.1303, 0.1633, 0.2136, 0.1858]],\n",
              "\n",
              "         [[0.1835, 0.1996, 0.1714, 0.1440, 0.1493, 0.1522],\n",
              "          [0.1122, 0.2190, 0.1456, 0.2217, 0.1875, 0.1140],\n",
              "          [0.1399, 0.2864, 0.1552, 0.1644, 0.1515, 0.1026],\n",
              "          [0.1848, 0.2312, 0.1709, 0.1358, 0.1408, 0.1364],\n",
              "          [0.2069, 0.1438, 0.1752, 0.1319, 0.1465, 0.1959],\n",
              "          [0.1077, 0.2347, 0.1430, 0.2231, 0.1856, 0.1058]],\n",
              "\n",
              "         [[0.1552, 0.2381, 0.1336, 0.1349, 0.1472, 0.1909],\n",
              "          [0.1395, 0.3163, 0.0905, 0.0824, 0.0958, 0.2755],\n",
              "          [0.1428, 0.3057, 0.1038, 0.1015, 0.1178, 0.2284],\n",
              "          [0.1760, 0.1170, 0.1940, 0.1853, 0.1697, 0.1580],\n",
              "          [0.1756, 0.0295, 0.2849, 0.2448, 0.1677, 0.0975],\n",
              "          [0.1679, 0.1039, 0.2054, 0.2084, 0.1897, 0.1247]]],\n",
              "\n",
              "\n",
              "        [[[0.2710, 0.1594, 0.1829, 0.1430, 0.1148, 0.1289],\n",
              "          [0.3221, 0.1497, 0.2001, 0.1248, 0.1058, 0.0974],\n",
              "          [0.1798, 0.1649, 0.1793, 0.1592, 0.1702, 0.1467],\n",
              "          [0.1715, 0.1641, 0.1818, 0.1586, 0.1812, 0.1428],\n",
              "          [0.0581, 0.1481, 0.1282, 0.1743, 0.3026, 0.1887],\n",
              "          [0.1031, 0.1546, 0.1766, 0.1571, 0.2763, 0.1323]],\n",
              "\n",
              "         [[0.0819, 0.1195, 0.1870, 0.1895, 0.2429, 0.1791],\n",
              "          [0.1120, 0.1428, 0.1768, 0.1826, 0.2204, 0.1654],\n",
              "          [0.1150, 0.1412, 0.1798, 0.1812, 0.2074, 0.1754],\n",
              "          [0.1229, 0.1489, 0.1745, 0.1797, 0.2096, 0.1644],\n",
              "          [0.1607, 0.1598, 0.1715, 0.1673, 0.1619, 0.1788],\n",
              "          [0.1773, 0.1695, 0.1649, 0.1633, 0.1569, 0.1681]],\n",
              "\n",
              "         [[0.1712, 0.1954, 0.1804, 0.1692, 0.1467, 0.1372],\n",
              "          [0.1570, 0.2875, 0.2131, 0.1684, 0.1074, 0.0665],\n",
              "          [0.1446, 0.2253, 0.1961, 0.1769, 0.1634, 0.0935],\n",
              "          [0.1734, 0.2199, 0.1903, 0.1695, 0.1308, 0.1161],\n",
              "          [0.1566, 0.1946, 0.1819, 0.1731, 0.1670, 0.1267],\n",
              "          [0.1458, 0.1796, 0.1759, 0.1741, 0.1925, 0.1321]],\n",
              "\n",
              "         [[0.1239, 0.0955, 0.1042, 0.1235, 0.3443, 0.2086],\n",
              "          [0.1492, 0.0904, 0.1081, 0.1349, 0.3475, 0.1698],\n",
              "          [0.1434, 0.1372, 0.1389, 0.1472, 0.2333, 0.1999],\n",
              "          [0.1337, 0.1695, 0.1548, 0.1486, 0.1784, 0.2150],\n",
              "          [0.1629, 0.2318, 0.2045, 0.1740, 0.0847, 0.1420],\n",
              "          [0.1015, 0.1912, 0.1505, 0.1306, 0.1533, 0.2729]]],\n",
              "\n",
              "\n",
              "        [[[0.2857, 0.2895, 0.0878, 0.1517, 0.1637, 0.0216],\n",
              "          [0.2921, 0.2773, 0.0897, 0.1549, 0.1620, 0.0240],\n",
              "          [0.3022, 0.2383, 0.0992, 0.1657, 0.1580, 0.0366],\n",
              "          [0.2035, 0.2245, 0.1421, 0.1680, 0.1799, 0.0820],\n",
              "          [0.1227, 0.1417, 0.1827, 0.1522, 0.1593, 0.2415],\n",
              "          [0.3119, 0.2324, 0.0976, 0.1666, 0.1550, 0.0366]],\n",
              "\n",
              "         [[0.1777, 0.1204, 0.1736, 0.1683, 0.2078, 0.1522],\n",
              "          [0.1690, 0.1519, 0.1715, 0.1685, 0.1784, 0.1608],\n",
              "          [0.1710, 0.1425, 0.1733, 0.1690, 0.1864, 0.1577],\n",
              "          [0.1744, 0.1795, 0.1448, 0.1573, 0.1557, 0.1883],\n",
              "          [0.1720, 0.1822, 0.1472, 0.1584, 0.1542, 0.1860],\n",
              "          [0.1288, 0.1085, 0.2698, 0.1929, 0.2073, 0.0927]],\n",
              "\n",
              "         [[0.1085, 0.1446, 0.2734, 0.1284, 0.2395, 0.1056],\n",
              "          [0.1148, 0.1363, 0.2837, 0.1464, 0.2321, 0.0867],\n",
              "          [0.1172, 0.1284, 0.2949, 0.1596, 0.2275, 0.0724],\n",
              "          [0.1276, 0.1616, 0.2181, 0.1337, 0.2113, 0.1476],\n",
              "          [0.1584, 0.1625, 0.1854, 0.1658, 0.1785, 0.1493],\n",
              "          [0.2129, 0.1239, 0.1727, 0.2889, 0.1306, 0.0710]],\n",
              "\n",
              "         [[0.1178, 0.1876, 0.1285, 0.1513, 0.1773, 0.2375],\n",
              "          [0.0840, 0.1230, 0.0757, 0.0923, 0.2138, 0.4112],\n",
              "          [0.0570, 0.1812, 0.0679, 0.1035, 0.1803, 0.4100],\n",
              "          [0.0841, 0.2253, 0.1068, 0.1479, 0.1656, 0.2703],\n",
              "          [0.1349, 0.1989, 0.1523, 0.1714, 0.1603, 0.1822],\n",
              "          [0.1829, 0.1854, 0.2037, 0.1969, 0.1293, 0.1018]]]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply attention and values to get reweighted values\n",
        "A = torch.matmul(attn_probs, V) # (batch_size, n_heads, Q_length, d_key)\n",
        "A.shape # ([3, 4, 6, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVG3Ut6Ue-pY",
        "outputId": "74484513-fd16-4513-91da-accbb39394f0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The concatenation reverses the split that was performed originally. The first step is to **transpose n_heads and Q_length**. The second step is to concatenate **n_heads and d_key back together to get d_model**.\n",
        "\n",
        "Once this is complete, **A will have a shape of (batch_size, Q_length, d_model).**"
      ],
      "metadata": {
        "id": "rQafYGqofkA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose from (3, 4, 6, 2) -> (3, 6, 4, 2)\n",
        "A = A.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "# reshape from (3, 6, 4, 2) -> (3, 6, 8) = (batch_size, Q_length, d_model)\n",
        "A = A.view(batch_size, -1, n_heads*d_key)\n",
        "\n",
        "A.shape # torch.Size([3, 6, 8]) == Input: torch.Size([3, 6, 8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbATCBnGfM1w",
        "outputId": "dbb04928-bfbd-4de1-aeff-b8191603ddbe"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MultiHeadAttention"
      ],
      "metadata": {
        "id": "qTUTPJpXgfLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model: int = 512, n_heads: int = 8, dropout: float = 0.1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        d_model:      dimension of embeddings\n",
        "        n_heads:      number of self attention heads\n",
        "        dropout:      probability of dropout occurring\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    assert d_model % n_heads == 0            # ensure an even num of heads\n",
        "    self.d_model = d_model                   # 512 dim\n",
        "    self.n_heads = n_heads                   # 8 heads\n",
        "    self.d_key = d_model // n_heads          # assume d_value equals d_key | 512/8=64\n",
        "\n",
        "    self.Wq = nn.Linear(d_model, d_model)    # query weights\n",
        "    self.Wk = nn.Linear(d_model, d_model)    # key weights\n",
        "    self.Wv = nn.Linear(d_model, d_model)    # value weights\n",
        "    self.Wo = nn.Linear(d_model, d_model)    # output weights\n",
        "\n",
        "    self.dropout = nn.Dropout(p=dropout)     # initialize dropout layer\n",
        "\n",
        "  def forward(self, query: torch,Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       query:         query vector         (batch_size, q_length, d_model)\n",
        "       key:           key vector           (batch_size, k_length, d_model)\n",
        "       value:         value vector         (batch_size, s_length, d_model)\n",
        "       mask:          mask for decoder\n",
        "\n",
        "    Returns:\n",
        "       output:        attention values     (batch_size, q_length, d_model)\n",
        "       attn_probs:    softmax scores       (batch_size, n_heads, q_length, k_length)\n",
        "    \"\"\"\n",
        "    batch_size = key.size(0)\n",
        "\n",
        "    # calculate query, key, and value tensors\n",
        "    Q = self.Wq(query)                       # (32, 10, 512) x (512, 512) = (32, 10, 512)\n",
        "    K = self.Wk(key)                         # (32, 10, 512) x (512, 512) = (32, 10, 512)\n",
        "    V = self.Wv(value)                       # (32, 10, 512) x (512, 512) = (32, 10, 512)\n",
        "\n",
        "    # split each tensor into n-heads to compute attention\n",
        "\n",
        "    # query tensor\n",
        "    Q = Q.view(batch_size,                   # (32, 10, 512) -> (32, 10, 8, 64)\n",
        "               -1,                           # -1 = q_length\n",
        "               self.n_heads,\n",
        "               self.d_key\n",
        "               ).permute(0, 2, 1, 3)         # (32, 10, 8, 64) -> (32, 8, 10, 64) = (batch_size, n_heads, q_length, d_key)\n",
        "    # key tensor\n",
        "    K = K.view(batch_size,                   # (32, 10, 512) -> (32, 10, 8, 64)\n",
        "               -1,                           # -1 = k_length\n",
        "               self.n_heads,\n",
        "               self.d_key\n",
        "               ).permute(0, 2, 1, 3)         # (32, 10, 8, 64) -> (32, 8, 10, 64) = (batch_size, n_heads, k_length, d_key)\n",
        "    # value tensor\n",
        "    V = V.view(batch_size,                   # (32, 10, 512) -> (32, 10, 8, 64)\n",
        "               -1,                           # -1 = v_length\n",
        "               self.n_heads,\n",
        "               self.d_key\n",
        "               ).permute(0, 2, 1, 3)         # (32, 10, 8, 64) -> (32, 8, 10, 64) = (batch_size, n_heads, v_length, d_key)\n",
        "\n",
        "    # computes attention\n",
        "    # scaled dot product -> QK^{T}\n",
        "    scaled_dot_prod = torch.matmul(Q,        # (32, 8, 10, 64) x (32, 8, 64, 10) -> (32, 8, 10, 10) = (batch_size, n_heads, q_length, k_length)\n",
        "                                   K.permute(0, 1, 3, 2)\n",
        "                                   ) / math.sqrt(self.d_key)      # sqrt(64)\n",
        "\n",
        "    # fill those positions of product as (-1e10) where mask positions are 0\n",
        "    if mask is not None:\n",
        "      scaled_dot_prod = scaled_dot_prod.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    # apply softmax\n",
        "    attn_probs = torch.softmax(scaled_dot_prod, dim=-1)\n",
        "\n",
        "    # multiply by values to get attention\n",
        "    A = torch.matmul(self.dropout(attn_probs), V)       # (32, 8, 10, 10) x (32, 8, 10, 64) -> (32, 8, 10, 64)\n",
        "                                                        # (batch_size, n_heads, q_length, k_length) x (batch_size, n_heads, v_length, d_key) -> (batch_size, n_heads, q_length, d_key)\n",
        "\n",
        "    # reshape attention back to (32, 10, 512)\n",
        "    A = A.permute(0, 2, 1, 3).contiguous()              # (32, 8, 10, 64) -> (32, 10, 8, 64)\n",
        "    A = A.view(batch_size, -1, self.n_heads*self.d_key) # (32, 10, 8, 64) -> (32, 10, 8*64) -> (32, 10, 512) = (batch_size, q_length, d_model)\n",
        "\n",
        "    # push through the final weight layer\n",
        "    output = self.Wo(A)                                 # (32, 10, 512) x (512, 512) = (32, 10, 512)\n",
        "\n",
        "    return output, attn_probs                           # return attn_probs for visualization of the scores\n"
      ],
      "metadata": {
        "id": "p8qAi70sgc1X"
      },
      "execution_count": 71,
      "outputs": []
    }
  ]
}